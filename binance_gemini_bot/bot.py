import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from supabase import create_client, Client
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import DataLoader, TensorDataset
import os

# ==========================================
# 1. í™˜ê²½ ì„¤ì • (ë³¸ì¸ì˜ ì •ë³´ë¡œ ìˆ˜ì •)
# ==========================================
SUPABASE_URL = ""
SUPABASE_KEY = ""
TABLE_NAME = "trading_data_1d"  # ìŠˆí¼ë² ì´ìŠ¤ í…Œì´ë¸” ì´ë¦„


# ==========================================
# 2. ìŠˆí¼ë² ì´ìŠ¤ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ==========================================
def fetch_data_from_supabase():
    print("ğŸŒ ìŠˆí¼ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

    # ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (í•„ìš”ì‹œ .range()ë¡œ ì¡°ì ˆ ê°€ëŠ¥)
    response = supabase.table(TABLE_NAME).select("*").order("timestamp").execute()
    df = pd.DataFrame(response.data)

    # ìˆ«ìí˜• ë³€í™˜ ë° ì •ë ¬
    numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'ma50', 'ma200']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df = df.dropna()  # ê²°ì¸¡ì¹˜ ì œê±°
    return df


# ==========================================
# 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ìƒì„±
# ==========================================
def prepare_data(df, window_size=24):
    features = ['open', 'high', 'low', 'close', 'volume', 'ma50', 'ma200']

    # [ë¼ë²¨ë§] 24ì‹œê°„ ë‚´ 3% ìˆ˜ìµ ë°œìƒ ì‹œ Target=1 (íŒŒë™ í¬ì°©)
    df['target'] = 0
    close_prices = df['close'].values
    high_prices = df['high'].values
    for i in range(len(df) - 24):
        future_max = np.max(high_prices[i + 1: i + 25])
        if (future_max - close_prices[i]) / close_prices[i] >= 0.03:
            df.at[df.index[i], 'target'] = 1

    data = df[features].values
    target = df['target'].values

    # ì •ê·œí™” (MinMax ìŠ¤ì¼€ì¼ë§)
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data)

    # LSTMìš© ì‹œí€€ìŠ¤ ìƒì„± (ê³¼ê±° 24ì‹œê°„ -> í˜„ì¬ ì˜ˆì¸¡)
    X, y = [], []
    for i in range(len(data_scaled) - window_size):
        X.append(data_scaled[i: i + window_size])
        y.append(target[i + window_size])

    return torch.tensor(np.array(X), dtype=torch.float32), \
        torch.tensor(np.array(y), dtype=torch.float32).unsqueeze(1), \
        scaler


# ==========================================
# 4. LSTM ëª¨ë¸ êµ¬ì¡° ì •ì˜
# ==========================================
class WaveLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers):
        super(WaveLSTM, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_dim, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        _, (hn, _) = self.lstm(x)
        out = self.fc(hn[-1])  # ë§ˆì§€ë§‰ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ ì‚¬ìš©
        return self.sigmoid(out)


# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ ë£¨í‹´ (í•™ìŠµ)
# ==========================================
if __name__ == "__main__":
    # 1. ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    try:
        df_raw = fetch_data_from_supabase()
        X_data, y_data, scaler = prepare_data(df_raw)

        # ë°ì´í„°ì…‹ ë¶„ë¦¬
        train_size = int(len(X_data) * 0.8)
        train_X, train_y = X_data[:train_size], y_data[:train_size]

        loader = DataLoader(TensorDataset(train_X, train_y), batch_size=32, shuffle=True)

        # 2. ëª¨ë¸ ì„¤ì •
        model = WaveLSTM(input_dim=7, hidden_dim=64, num_layers=2)
        criterion = nn.BCELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        # 3. í•™ìŠµ
        print("ğŸš€ LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Supabase Data)...")
        for epoch in range(100):
            model.train()
            total_loss = 0
            for batch_X, batch_y in loader:
                optimizer.zero_grad()
                pred = model(batch_X)
                loss = criterion(pred, batch_y)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch + 1}/100], Loss: {total_loss / len(loader):.4f}")

        # 4. ëª¨ë¸ ì €ì¥
        torch.save(model.state_dict(), "wave_lstm_model.pth")
        print("âœ… í•™ìŠµ ì™„ë£Œ! 'wave_lstm_model.pth' ì €ì¥ë¨.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
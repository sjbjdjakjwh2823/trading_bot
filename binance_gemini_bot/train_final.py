import pandas as pd
import numpy as np
import pandas_ta as ta
import torch
import torch.nn as nn
import re
from supabase import create_client
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import DataLoader, TensorDataset

# ==========================================
# 1. ì„¤ì • (ì‚¬ìš©ì ì •ë³´ ì…ë ¥)
# ==========================================
URL = ""
RAW_KEY = "" # ìŠˆí¼ë² ì´ìŠ¤ 'anon' ë˜ëŠ” 'service_role' í‚¤

# í‚¤ê°’ì—ì„œ í˜¹ì‹œ ëª¨ë¥¼ íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì œê±°
KEY = re.sub(r'[^\x00-\x7F]+', '', RAW_KEY).strip()
supabase = create_client(URL, KEY)

# ==========================================
# 2. ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (1,000ê°œ ì œí•œ í•´ì œ)
# ==========================================
def fetch_all_data(table_name):
    print(f"ğŸ“¡ {table_name} ëª¨ë“  ë°ì´í„° ë¡œë“œ ì¤‘...")
    all_data = []
    last_timestamp = 0
    
    while True:
        res = supabase.table(table_name).select("*")\
            .gt("timestamp", last_timestamp)\
            .order("timestamp")\
            .limit(1000).execute()
        
        if not res.data:
            break
            
        all_data.extend(res.data)
        last_timestamp = res.data[-1]['timestamp']
        
        if len(all_data) % 10000 == 0:
            print(f"   -> {len(all_data)}ê°œ ì™„ë£Œ...")

    df = pd.DataFrame(all_data)
    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
    for col in ['open', 'high', 'low', 'close', 'volume']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df.sort_values('datetime').reset_index(drop=True)

# ==========================================
# 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³‘í•©
# ==========================================
def prepare_data():
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    df_15m = fetch_all_data("trading_data_15m")
    df_1h = fetch_all_data("trading_data_1h")
    df_4h = fetch_all_data("trading_data_4h")
    df_1d = fetch_all_data("trading_data_1d")

    print("ğŸ“ˆ ë³´ì¡°ì§€í‘œ ê³„ì‚° ë° ë³‘í•© ì¤‘...")
    
    # ê° ì‹œê°„ëŒ€ë³„ RSI ê³„ì‚°
    for df, sfx in [(df_15m, ""), (df_1h, "_1h"), (df_4h, "_4h"), (df_1d, "_1d")]:
        df[f'rsi{sfx}'] = ta.rsi(df['close'], length=14)

    # 15ë¶„ë´‰ ì „ìš© ì§€í‘œ (BB, MACD)
    bb = ta.bbands(df_15m['close'], length=20, std=2)
    df_15m['bb_u'] = bb.iloc[:, 2] # Upper
    df_15m['bb_l'] = bb.iloc[:, 0] # Lower
    
    macd = ta.macd(df_15m['close'])
    df_15m['macd'] = macd.iloc[:, 0]
    df_15m['macd_s'] = macd.iloc[:, 1]

    # ë©€í‹° íƒ€ì„í”„ë ˆì„ ë³‘í•© (ì‹œê°„ ê¸°ì¤€ ì •ë ¬)
    merged = pd.merge_asof(df_15m, df_1h[['datetime', 'rsi_1h']], on='datetime', direction='backward')
    merged = pd.merge_asof(merged, df_4h[['datetime', 'rsi_4h']], on='datetime', direction='backward')
    final_df = pd.merge_asof(merged, df_1d[['datetime', 'rsi_1d']], on='datetime', direction='backward')

    # Target ìƒì„±: 4ì‹œê°„ ë’¤ ê°€ê²©ì´ ì˜¬ëìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0
    final_df['target'] = (final_df['close'].shift(-16) > final_df['close']).astype(int)
    
    # ê²°ì¸¡ì¹˜ ì œê±° ë° ë°ì´í„° ì œí•œ (ìµœê·¼ 5ë§Œê°œë§Œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„ ìµœì í™”)
    final_df = final_df.dropna().iloc[-50000:]
    
    print(f"âœ… ìµœì¢… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(final_df)}ê°œ")
    return final_df

# ==========================================
# 4. LSTM ëª¨ë¸ ì •ì˜
# ==========================================
class PricePredictor(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers):
        super(PricePredictor, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_dim, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)

# ==========================================
# 5. ì‹¤í–‰ ë©”ì¸ ë£¨í”„
# ==========================================
if __name__ == "__main__":
    try:
        df = prepare_data()
        
        # 1. íŠ¹ì„± ì„ íƒ ë° ë°ì´í„° ì¤€ë¹„
        features = ['close', 'volume', 'rsi', 'bb_u', 'bb_l', 'macd', 'macd_s', 'rsi_1h', 'rsi_4h', 'rsi_1d']
        data_x = df[features].values
        data_y = df['target'].values

        # 2. ìŠ¤ì¼€ì¼ë§
        scaler = MinMaxScaler()
        data_x_scaled = scaler.fit_transform(data_x)

        # 3. ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜
        def create_sequences(data, target, seq_length):
            x, y = [], []
            for i in range(len(data) - seq_length):
                x.append(data[i:i+seq_length])
                y.append(target[i+seq_length])
            return np.array(x), np.array(y)

        X, y = create_sequences(data_x_scaled, data_y, 60)
        
        # 4. í…ì„œ ë³€í™˜ ë° ë°ì´í„°ë¡œë” ì„¤ì • (ì´ ë¶€ë¶„ì´ í•µì‹¬!)
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.FloatTensor(y).view(-1, 1)
        
        # ë°ì´í„°ë¥¼ 64ê°œì”© ìª¼ê°œì„œ ëª¨ë¸ì— ë„£ìŠµë‹ˆë‹¤ (ë©”ëª¨ë¦¬ í­ì£¼ ë°©ì§€)
        dataset = TensorDataset(X_tensor, y_tensor)
        train_loader = DataLoader(dataset, batch_size=64, shuffle=True)

        # 5. ëª¨ë¸ ì„¤ì •
        # ë§Œì•½ NVIDIA ê·¸ë˜í”½ì¹´ë“œê°€ ìˆë‹¤ë©´ cudaë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: {device}")
        
        model = PricePredictor(input_dim=len(features), hidden_dim=64, num_layers=2).to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.BCELoss()
        
        # 6. í•™ìŠµ ë£¨í”„ (ë°°ì¹˜ ë‹¨ìœ„ í•™ìŠµ)
        print(f"ğŸš€ í•™ìŠµ ì‹œì‘... (ì´ {len(train_loader)}ê°œ ë°°ì¹˜)")
        for epoch in range(1, 11):
            model.train()
            epoch_loss = 0
            
            for batch_x, batch_y in train_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                
                optimizer.zero_grad()
                output = model(batch_x)
                loss = criterion(output, batch_y)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(train_loader)
            print(f"âœ… Epoch [{epoch}/10], í‰ê·  Loss: {avg_loss:.4f}")

        # 7. ëª¨ë¸ ì €ì¥
        torch.save(model.state_dict(), "trading_model.pth")
        print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: trading_model.pth")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")